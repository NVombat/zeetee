{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Data Merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/nvombat/Desktop/z3r0_7ru57/research/experiments/hpc/experiment3\"\n",
    "output_dir = root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_combined = pd.DataFrame()\n",
    "e2_combined = pd.DataFrame()\n",
    "\n",
    "# Loop through each folder in the root directory\n",
    "for folder in sorted(os.listdir(root_dir)):\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "\n",
    "    # Loop through each subfolder in the root directory\n",
    "    for sub_folder in sorted(os.listdir(folder_path)):\n",
    "        sub_folder_path = os.path.join(folder_path, sub_folder)\n",
    "\n",
    "        if os.path.isdir(sub_folder_path):\n",
    "            # Find the CSV files in the folder\n",
    "            for file in os.listdir(sub_folder_path):\n",
    "                if file.endswith(\".csv\"):\n",
    "                    file_path = os.path.join(sub_folder_path, file)\n",
    "\n",
    "                    if \"experiment_data_e1\" in file:\n",
    "                        df_e1 = pd.read_csv(file_path)\n",
    "                        e1_combined = pd.concat([e1_combined, df_e1], ignore_index=True)\n",
    "                    elif \"experiment_data_e2\" in file:\n",
    "                        df_e2 = pd.read_csv(file_path)\n",
    "                        e2_combined = pd.concat([e2_combined, df_e2], ignore_index=True)\n",
    "\n",
    "# Save the concatenated DataFrames\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "e1_combined.to_csv(os.path.join(output_dir, 'concatenated_e1.csv'), index=False)\n",
    "e2_combined.to_csv(os.path.join(output_dir, 'concatenated_e2.csv'), index=False)\n",
    "\n",
    "print(\"Concatenation Complete. Files Saved To: \", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Data Analyzer & Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean, Median and Standard Deviation of Merged Instance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_concat_path = os.path.join(root_dir, \"concatenated_e1.csv\")\n",
    "e2_concat_path = os.path.join(root_dir, \"concatenated_e2.csv\")\n",
    "\n",
    "e1_data = pd.read_csv(e1_concat_path)\n",
    "e2_data = pd.read_csv(e2_concat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(df: pd.DataFrame, encoding_name: str):\n",
    "    \"\"\"\n",
    "    Calculate mean, median, and standard deviation for selected columns grouped by 'N'\n",
    "\n",
    "    Args:\n",
    "        df: Input data for an encoding\n",
    "        encoding_name: The name of the encoding ('E1', 'E2', etc.)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Statistics table with mean, median, and std for each column grouped by 'N'.\n",
    "    \"\"\"\n",
    "    # Columns to calculate statistics for\n",
    "    columns_to_analyze = ['num_clauses', 'num_variables', 'num_literals']\n",
    "\n",
    "    # Group by 'N' and calculate mean, median, std\n",
    "    stats = df.groupby('N')[columns_to_analyze].agg(['mean', 'median', 'std']).reset_index()\n",
    "\n",
    "    # Flatten multi-level column index\n",
    "    stats.columns = ['_'.join(col).strip('_') if col[1] else col[0] for col in stats.columns]\n",
    "\n",
    "    # Add encoding as the first column\n",
    "    stats.insert(0, 'encoding', encoding_name)\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "e1_stats = calculate_statistics(e1_data, \"E1\")\n",
    "e2_stats = calculate_statistics(e2_data, \"E2\")\n",
    "\n",
    "combined_stats = pd.concat([e1_stats, e2_stats], ignore_index=True)\n",
    "\n",
    "stats_output_file = os.path.join(output_dir, 'encoding_statistics.csv')\n",
    "combined_stats.to_csv(stats_output_file, index=False)\n",
    "\n",
    "print(\"Statistics Calculated and Saved To: \", stats_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics Calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timed Out Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding 1:\n",
    "tmo_count_e1 = e1_data['status'].value_counts().get('TMO', 0)\n",
    "tmo_count_e2 = e2_data['status'].value_counts().get('TMO', 0)\n",
    "\n",
    "print(f\"Count of TMO [E1]: {tmo_count_e1}\")\n",
    "print(f\"Count of TMO [E2]: {tmo_count_e2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Solving Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_solving_time_e1 = e1_data.loc[e1_data['status'] == 'SLV', 'solving_time'].sum()\n",
    "total_solving_time_e2 = e2_data.loc[e2_data['status'] == 'SLV', 'solving_time'].sum()\n",
    "\n",
    "print(f\"Total solving time for SLV instances [E1]: {total_solving_time_e1}\")\n",
    "print(f\"Total solving time for SLV instances [E2]: {total_solving_time_e2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Mean, Median and STD for Encoding1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_e1 = {\n",
    "    'Metric': [],\n",
    "    'Mean': [],\n",
    "    'Median': [],\n",
    "    'Standard Deviation': []\n",
    "}\n",
    "\n",
    "columns_to_analyze = ['num_clauses', 'num_variables', 'num_literals']\n",
    "\n",
    "for column in columns_to_analyze:\n",
    "    statistics_e1['Metric'].append(column)\n",
    "    statistics_e1['Mean'].append(e1_data[column].mean())\n",
    "    statistics_e1['Median'].append(e1_data[column].median())\n",
    "    statistics_e1['Standard Deviation'].append(e1_data[column].std())\n",
    "\n",
    "stats_e1 = pd.DataFrame(statistics_e1)\n",
    "\n",
    "print(stats_e1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Mean, Median and STD for Encoding2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_e2 = {\n",
    "    'Metric': [],\n",
    "    'Mean': [],\n",
    "    'Median': [],\n",
    "    'Standard Deviation': []\n",
    "}\n",
    "\n",
    "columns_to_analyze = ['num_clauses', 'num_variables', 'num_literals']\n",
    "\n",
    "for column in columns_to_analyze:\n",
    "    statistics_e2['Metric'].append(column)\n",
    "    statistics_e2['Mean'].append(e2_data[column].mean())\n",
    "    statistics_e2['Median'].append(e2_data[column].median())\n",
    "    statistics_e2['Standard Deviation'].append(e2_data[column].std())\n",
    "\n",
    "stats_e2 = pd.DataFrame(statistics_e2)\n",
    "\n",
    "print(stats_e2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rgp-solver--3BMeHP1-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
