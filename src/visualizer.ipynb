{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Data Merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/nvombat/Desktop/z3r0_7ru57/research/experiments/hpc/experiment1\"\n",
    "output_dir = root_dir\n",
    "\n",
    "e1_combined = pd.DataFrame()\n",
    "e2_combined = pd.DataFrame()\n",
    "\n",
    "# Loop through each folder in the root directory\n",
    "for folder in sorted(os.listdir(root_dir)):\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Find the CSV files in the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".csv\"):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "\n",
    "                if \"experiment_data_e1\" in file:\n",
    "                    df_e1 = pd.read_csv(file_path)\n",
    "                    e1_combined = pd.concat([e1_combined, df_e1], ignore_index=True)\n",
    "                elif \"experiment_data_e2\" in file:\n",
    "                    df_e2 = pd.read_csv(file_path)\n",
    "                    e2_combined = pd.concat([e2_combined, df_e2], ignore_index=True)\n",
    "\n",
    "# Save the concatenated DataFrames\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "e1_combined.to_csv(os.path.join(output_dir, 'concatenated_e1.csv'), index=False)\n",
    "e2_combined.to_csv(os.path.join(output_dir, 'concatenated_e2.csv'), index=False)\n",
    "\n",
    "print(\"Concatenation Complete. Files Saved To: \", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Data Visualizer & Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean, Median and Standard Deviation of Merged Instance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_concat_path = os.path.join(root_dir, \"concatenated_e1.csv\")\n",
    "e2_concat_path = os.path.join(root_dir, \"concatenated_e2.csv\")\n",
    "\n",
    "e1_data = pd.read_csv(e1_concat_path)\n",
    "e2_data = pd.read_csv(e2_concat_path)\n",
    "\n",
    "columns_to_analyze = ['num_clauses', 'num_variables', 'num_literals']\n",
    "\n",
    "def plot_statistics(data, encoding_type):\n",
    "    # Group by N - calculates the mean, median, and standard deviation for each N\n",
    "    grouped = data.groupby('N')[columns_to_analyze].agg(['mean', 'median', 'std'])\n",
    "\n",
    "    # Flatten the multi-index columns\n",
    "    grouped.columns = ['_'.join(col) for col in grouped.columns]\n",
    "\n",
    "    for column in columns_to_analyze:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Plot mean, median, std\n",
    "        plt.plot(grouped.index, grouped[f'{column}_mean'], label='Mean', marker='o')\n",
    "        plt.plot(grouped.index, grouped[f'{column}_median'], label='Median', marker='x')\n",
    "        plt.plot(grouped.index, grouped[f'{column}_std'], label='Std Dev', marker='s')\n",
    "\n",
    "        plt.title(f'{column.capitalize()} Instance Data Statistics for {encoding_type}')\n",
    "        plt.xlabel('N')\n",
    "        plt.ylabel(column.capitalize())\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "plot_statistics(e1_data, 'E1')\n",
    "plot_statistics(e2_data, 'E2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean, Median and Standard Deviation of Individual Instance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = \"/home/nvombat/Desktop/z3r0_7ru57/research/experiments/hpc/\"\n",
    "exp_dir = \"experiment1\"\n",
    "\n",
    "sub_dirs = [\"N100\", \"N200\", \"N300\", \"N400\", \"N500\", \"N600\", \"N700\", \"N800\", \"N900\", \"N1000\"]\n",
    "selected_sub_dir = sub_dirs[0]\n",
    "\n",
    "target_dir = os.path.join(src_dir, exp_dir, selected_sub_dir)\n",
    "print(f\"TARGET DIR: {target_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = \"experiment_data_e1.csv\"\n",
    "file_path1 = os.path.join(target_dir, filename1)\n",
    "\n",
    "print(f\"FILE PATH [E1]: {file_path1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(file_path1)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages_e1 = df1[['num_clauses', 'num_variables', 'num_literals']].mean()\n",
    "print(\"[E1] Averages: \\n\", averages_e1)\n",
    "\n",
    "print(\"--------------------\")\n",
    "\n",
    "median_values_e1 = df1[['num_clauses', 'num_variables', 'num_literals']].median()\n",
    "print(\"[E1] Median Values: \\n\", median_values_e1)\n",
    "\n",
    "print(\"--------------------\")\n",
    "\n",
    "std_values_e1 = df1[['num_clauses', 'num_variables', 'num_literals']].std()\n",
    "print(\"[E1] Standard Deviation Values: \\n\", std_values_e1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = \"experiment_data_e2.csv\"\n",
    "file_path2 = os.path.join(target_dir, filename2)\n",
    "\n",
    "print(f\"FILE PATH [E2]: {file_path2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(file_path2)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages_e2 = df2[['num_clauses', 'num_variables', 'num_literals']].mean()\n",
    "print(\"[E2] Averages: \\n\", averages_e2)\n",
    "\n",
    "print(\"--------------------\")\n",
    "\n",
    "median_values_e2 = df2[['num_clauses', 'num_variables', 'num_literals']].median()\n",
    "print(\"[E2] Median Values: \\n\", median_values_e2)\n",
    "\n",
    "print(\"--------------------\")\n",
    "\n",
    "std_values_e2 = df2[['num_clauses', 'num_variables', 'num_literals']].std()\n",
    "print(\"[E2] Standard Deviation Values: \\n\", std_values_e2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rgp-solver--3BMeHP1-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
